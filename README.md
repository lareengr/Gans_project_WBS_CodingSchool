# Gans_project at WBS Coding School
Project within the DataScience Bootcamp to set up an automated data pipeline

The tasked was to develope an automated data pipeline in the cloud to collect, transform, and store data from various sources. It involvse two major phases: building a local pipeline (showcased here) and migrating it to the cloud.

Major aspects:
  1. Web scraping
  2. APIs
  3. SQL database

![image](https://github.com/user-attachments/assets/1d1788c4-7839-435c-ad6e-b8da075d6057)

Skills applied:
- Collect data from the internet by writing a web scraping script using Python’s library beautifulsoup.
- Collect data from the internet through APIs
- Navigate JSON files and find the information you need.
- Clean data using either Python’s string operations, str methods from the Pandas library or regex.
- Write for loops and list comprehensions on Python to perform tasks iteratively.
- Structure your Python code as functions.
- Set up a MySQL database.
- Create an SQL data model, crafting the relationships between tables.
- Create MySQL tables with the appropriate data types, constraints and keys.
- Populate MySQL tables with collected data through INSERT queries executed from a Python script.

