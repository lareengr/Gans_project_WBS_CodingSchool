{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching city data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for Berlin, Munich, Hamburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lat_lon_parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\"]\n",
    "\n",
    "city_coordinates = []\n",
    "city_population = []\n",
    "for city in cities:\n",
    "    url = f\"https://en.wikipedia.org/wiki/{city}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    population_header = soup.find_all(class_='infobox-header',colspan=\"2\")[2]\n",
    "    \n",
    "    city_coordinates.append ({\n",
    "        'city': city,\n",
    "        'latitude': parse(soup.find(\"span\", class_=\"latitude\").text),\n",
    "        'longitude':parse(soup.find(\"span\", class_=\"longitude\").text),\n",
    "        'country': (soup.find_all(class_=\"infobox-data\")[0].a.text),\n",
    "        'population': (population_header.find_next('td').text.replace(\",\", \"\")),\n",
    "        'timestamp_population': datetime.today().date()\n",
    "    })\n",
    "    city_population.append ({\n",
    "        'city': city,\n",
    "        'population': (population_header.find_next('td').text.replace(\",\", \"\")),\n",
    "        'timestamp_population': datetime.today().date()\n",
    "    })\n",
    "\n",
    "city_coordinates_df = pd.DataFrame(city_coordinates)\n",
    "city_population_df = pd.DataFrame(city_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m port \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3306\u001b[39m\n\u001b[1;32m     12\u001b[0m engine \u001b[38;5;241m=\u001b[39m sqlalchemy\u001b[38;5;241m.\u001b[39mcreate_engine(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmysql+mysqlconnector://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mcity_coordinates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mengine, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m city_population\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m'\u001b[39m, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mengine, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_sql'"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pymysql\n",
    "import cryptography\n",
    "import os \n",
    "\n",
    "schema = \"sql_workshop\"\n",
    "host = \"127.0.0.1\"\n",
    "user = \"root\"\n",
    "password = os.getenv(\"con_password\") \n",
    "port = 3306\n",
    "\n",
    "engine = sqlalchemy.create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{schema}\")\n",
    "\n",
    "city_coordinates.to_sql('coordinates', if_exists='append', con=engine, index=False)\n",
    "city_population.to_sql('population', if_exists='append', con=engine, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for fetching city data when provided list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lat_lon_parser import parse\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def retrieve_and_send_city_data():\n",
    "    engine = create_connection_string()\n",
    "    cities = ['New York', 'Los Angeles', 'Berlin', 'London']  # Example list of cities\n",
    "    city_coordinates, city_population = fetch_city_information(cities)\n",
    "    store_city_data(city_coordinates, city_population, engine)\n",
    "    return \"Data has been updated\"\n",
    "\n",
    "def create_connection_string():\n",
    "    schema = \"sql_workshop\"\n",
    "    host = \"127.0.0.1\"\n",
    "    user = \"root\"\n",
    "    password = os.getenv(\"con_password\") \n",
    "    port = 3306\n",
    "    return create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{schema}')\n",
    "\n",
    "def fetch_city_information(cities):\n",
    "    city_coordinates = []\n",
    "    city_population = []\n",
    "\n",
    "    for city in cities:\n",
    "        url = f\"https://en.wikipedia.org/wiki/{city}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            # Latitude and longitude scraping (might not be available for all cities)\n",
    "            latitude = parse(soup.find(\"span\", class_=\"latitude\").text) if soup.find(\"span\", class_=\"latitude\") else None\n",
    "            longitude = parse(soup.find(\"span\", class_=\"longitude\").text) if soup.find(\"span\", class_=\"longitude\") else None\n",
    "            population_header = soup.find_all(class_='infobox-header', colspan=\"2\")[2]\n",
    "            population = population_header.find_next('td').text.replace(\",\", \"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping city {city}: {e}\")\n",
    "            latitude, longitude, population = None, None, None\n",
    "\n",
    "        city_coordinates.append({\n",
    "            'city': city,\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'country': soup.find_all(class_=\"infobox-data\")[0].a.text if soup.find_all(class_=\"infobox-data\") else None,\n",
    "            'population': population,\n",
    "            'timestamp_population': datetime.today().date()\n",
    "        })\n",
    "\n",
    "        city_population.append({\n",
    "            'city': city,\n",
    "            'population': population,\n",
    "            'timestamp_population': datetime.today().date()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(city_coordinates), pd.DataFrame(city_population)\n",
    "\n",
    "def store_city_data(city_coordinates, city_population, engine):\n",
    "    city_coordinates.to_sql('coordinates', if_exists='append', con=engine, index=False)\n",
    "    city_population.to_sql('population', if_exists='append', con=engine, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching weather forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def insert_weather_data():\n",
    "    engine = connection()\n",
    "    cities_df = fetch_cities_data(engine)\n",
    "    weather_df = fetch_weather_forecast(cities_df, engine)\n",
    "    store_weather_data(weather_df, engine)\n",
    "    return \"Weather data successfully added\"\n",
    "\n",
    "# Establish database connection\n",
    "def connection():\n",
    "    schema = \"sql_workshop\"\n",
    "    host = \"127.0.0.1\" \n",
    "    user = \"root\"\n",
    "    password = os.getenv(\"con_password\")\n",
    "    port = 3306\n",
    "    \n",
    "    db_url = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{schema}\"\n",
    "    engine = create_engine(db_url)\n",
    "    return engine\n",
    "\n",
    "# Fetch city coordinates from database\n",
    "def fetch_cities_data(engine):\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT c.name, co.longitude, co.latitude\n",
    "        FROM city c\n",
    "        JOIN coordinates co ON c.city_id = co.city_id\n",
    "    \"\"\"\n",
    "    coordinates = pd.read_sql(query, con=engine)\n",
    "    return coordinates.set_index(\"name\")[[\"longitude\", \"latitude\"]].to_dict(orient=\"index\")\n",
    "\n",
    "# Fetch weather data from OpenWeather API\n",
    "def fetch_weather_forecast(cities_coordinates, engine):\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    api_key = os.getenv(\"weather_key\") \n",
    "\n",
    "    weather_data = []\n",
    "    retrieval_time = datetime.now(berlin_timezone).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    for city, coords in cities_coordinates.items():\n",
    "        latitude = coords[\"latitude\"]\n",
    "        longitude = coords[\"longitude\"]\n",
    "\n",
    "        url = f\"https://api.openweathermap.org/data/2.5/forecast?lat={latitude}&lon={longitude}&appid={api_key}&units=metric\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            forecast = response.json()\n",
    "            city_id_query = f\"SELECT city_id FROM city WHERE name = '{city}'\"\n",
    "            city_id_result = pd.read_sql(city_id_query, con=engine)\n",
    "\n",
    "            city_id = city_id_result.iloc[0]['city_id'] if not city_id_result.empty else None\n",
    "\n",
    "            for entry in forecast[\"list\"]:\n",
    "                weather_data.append({\n",
    "                    \"name\": city,\n",
    "                    \"date_time\": entry[\"dt_txt\"],\n",
    "                    \"min_temperature_(°C)\": entry[\"main\"][\"temp_min\"],\n",
    "                    \"max_temperature_(°C)\": entry[\"main\"][\"temp_max\"],\n",
    "                    \"feels_like_(°C)\": entry['main']['feels_like'],\n",
    "                    \"humidity_(%)\": entry[\"main\"][\"humidity\"],\n",
    "                    \"wind_speed_(m/s)\": entry[\"wind\"][\"speed\"],\n",
    "                    \"rain_(mm_last_3h)\": entry.get(\"rain\", {}).get(\"3h\", 0),\n",
    "                    \"weather\": entry[\"weather\"][0][\"description\"],\n",
    "                    \"retrieval_time\": retrieval_time,\n",
    "                    \"city_id\": city_id\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Failed to fetch weather for {city}: {response.status_code}\")\n",
    "\n",
    "    return pd.DataFrame(weather_data)\n",
    "\n",
    "# Store data in MySQL database\n",
    "def store_weather_data(weather_df, engine):\n",
    "    weather_df.to_sql(name='weather_forecast', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching airpot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def insert_airport_data():\n",
    "    engine = connection()\n",
    "    cities_df = fetch_city_coordinates(engine)\n",
    "    airports_df = get_airports_with_city_id(cities_df, engine)\n",
    "    store_airport_data(airports_df, engine)\n",
    "    return \"Airport data successfully added\"\n",
    "\n",
    "# Establish database connection\n",
    "def connection():\n",
    "    schema = \"sql_workshop\"\n",
    "    host = \"127.0.0.1\" \n",
    "    user = \"root\"\n",
    "    password = os.getenv(\"con_password\")  \n",
    "    port = 3306\n",
    "    \n",
    "    db_url = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{schema}\"\n",
    "    engine = create_engine(db_url)\n",
    "    return engine\n",
    "\n",
    "# Fetch city coordinates from database\n",
    "def fetch_city_coordinates(engine):\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT c.name, co.longitude, co.latitude\n",
    "        FROM city c\n",
    "        JOIN coordinates co ON c.city_id = co.city_id\n",
    "    \"\"\"\n",
    "    coordinates = pd.read_sql(query, con=engine)\n",
    "    return coordinates.set_index(\"name\")[[\"longitude\", \"latitude\"]].to_dict(orient=\"index\")\n",
    "\n",
    "# Fetch airport data from an API using city coordinates\n",
    "def get_airports_with_city_id(cities_coordinates, engine):\n",
    "    api_key = os.getenv(\"flight_key\")  \n",
    "    \n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": api_key,\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    url = \"https://aerodatabox.p.rapidapi.com/airports/search/location\"\n",
    "    \n",
    "    all_airports = []\n",
    "\n",
    "    for city_name, coords in cities_coordinates.items():\n",
    "        latitude = coords[\"latitude\"]\n",
    "        longitude = coords[\"longitude\"]\n",
    "        \n",
    "        querystring = {\"lat\": latitude, \"lon\": longitude, \"radiusKm\": \"50\", \"limit\": \"3\", \"withFlightInfoOnly\": \"true\"}\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            airports = pd.json_normalize(data.get('items', []))\n",
    "            \n",
    "            # Fetch city_id from the database\n",
    "            city_id_query = f\"SELECT city_id FROM city WHERE name = '{city_name}'\"\n",
    "            city_id_result = pd.read_sql(city_id_query, con=engine)\n",
    "\n",
    "            if not city_id_result.empty:\n",
    "                city_id = city_id_result.iloc[0]['city_id']\n",
    "                airports['city_id'] = city_id  # Add city_id to the dataframe\n",
    "            else:\n",
    "                print(f\"City {city_name} not found in the city table.\")\n",
    "            \n",
    "            all_airports.append(airports)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for city: {city_name}, status code: {response.status_code}\")\n",
    "    \n",
    "    if all_airports:\n",
    "        return pd.concat(all_airports, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no data is fetched\n",
    "\n",
    "# Store airport data in the database\n",
    "def store_airport_data(airports_df, engine):\n",
    "    airports_df.to_sql(name='airport_data', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching flight arrival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def insert_flight_data():\n",
    "    engine = connection()\n",
    "    airport_dict = fetch_airport_data(engine)\n",
    "    flight_df = fetch_flight_arrivals(airport_dict, engine)\n",
    "    store_flight_data(flight_df, engine)\n",
    "    return \"Flight data successfully added\"\n",
    "\n",
    "# Establish database connection\n",
    "def connection():\n",
    "    schema = \"sql_workshop\"\n",
    "    host = \"127.0.0.1\" \n",
    "    user = \"root\"\n",
    "    password = os.getenv(\"con_password\") \n",
    "    port = 3306\n",
    "    \n",
    "    db_url = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{schema}\"\n",
    "    engine = create_engine(db_url)\n",
    "    return engine\n",
    "\n",
    "def fetch_airport_data(engine):\n",
    "    query = \"\"\"SELECT DISTINCT city_id, iata FROM airport \"\"\"\n",
    "    airports = pd.read_sql(query, con=engine)\n",
    "    return airports.to_dict(orient='index')\n",
    "\n",
    "# Fetch flight arrival data from Aerodatabox API\n",
    "def fetch_flight_arrivals(airport_dict, engine):\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    today = datetime.now(berlin_timezone).date()\n",
    "    tomorrow = today + timedelta(days=1)\n",
    "\n",
    "    times = [[\"00:00\", \"11:59\"],\n",
    "             [\"12:00\", \"23:59\"]]\n",
    "\n",
    "    arrivals = {}\n",
    "    arrival_data = []\n",
    "    api_key = os.getenv(\"flight_key\") \n",
    "\n",
    "    for city, airport in airport_dict.items():\n",
    "        iata = airport['iata']\n",
    "        city_id = airport['city_id']\n",
    "\n",
    "        for time_range in times:\n",
    "            url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/iata/{iata}/{tomorrow}T{time_range[0]}/{tomorrow}T{time_range[1]}\"\n",
    "\n",
    "            querystring = {\n",
    "                \"direction\": \"Arrival\",\n",
    "                \"withCancelled\": \"true\",\n",
    "                \"withCodeshared\": \"true\",\n",
    "                \"withCargo\": \"false\",\n",
    "                \"withPrivate\": \"true\",\n",
    "                \"withLocation\": \"false\"\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                \"x-rapidapi-key\": api_key,\n",
    "                \"x-rapidapi-host\": \"aerodatabox.p.rapidapi.com\"\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, headers=headers, params=querystring)\n",
    "            retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'arrivals' in data:\n",
    "                    if city_id not in arrivals:\n",
    "                        arrivals[city_id] = {'iata': iata, 'arrivals': []}\n",
    "                    arrivals[city_id]['arrivals'].extend(data['arrivals'])\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch arrivals for {city}: {response.status_code}\")\n",
    "\n",
    "    for city_id, arrival in arrivals.items():\n",
    "        for entry in arrival[\"arrivals\"]:\n",
    "            movement = entry.get('movement', {})\n",
    "            arrival_data.append({\n",
    "                'city_id': city_id,\n",
    "                'icao': movement.get('airport', {}).get('icao', 'Unknown'),\n",
    "                'iata': movement.get('airport', {}).get('iata', 'Unknown'),\n",
    "                'name': movement.get('airport', {}).get('name', 'Unknown'),\n",
    "                'timeZone': movement.get('airport', {}).get('timeZone', 'Unknown'),\n",
    "                'scheduledTime_local': movement.get('scheduledTime', {}).get('local', 'Unknown'),\n",
    "                'revisedTime_local': movement.get('revisedTime', {}).get('local', 'Unknown'),\n",
    "                'terminal': movement.get('terminal', 'Unknown'),\n",
    "                \"data_retrieved_at\": retrieval_time\n",
    "            })\n",
    "\n",
    "    df_arrivals = pd.DataFrame(arrival_data)\n",
    "\n",
    "    df_arrivals['scheduledTime_local'] = pd.to_datetime(df_arrivals['scheduledTime_local'], errors='coerce').dt.tz_localize(None)\n",
    "    df_arrivals['revisedTime_local'] = pd.to_datetime(df_arrivals['revisedTime_local'], errors='coerce').dt.tz_localize(None)\n",
    "    df_arrivals[\"data_retrieved_at\"] = pd.to_datetime(df_arrivals[\"data_retrieved_at\"])\n",
    "\n",
    "    return df_arrivals\n",
    "\n",
    "# Store data in MySQL database\n",
    "def store_flight_data(flight_df, engine):\n",
    "    flight_df.to_sql(name='flight', con=engine, if_exists='append', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
